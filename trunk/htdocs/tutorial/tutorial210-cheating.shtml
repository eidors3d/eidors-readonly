<!--#include virtual="./nav-sidebar.shtml" -->
<H2>Cheating with EIDORS</H2>

<center>
Andy Adler, William R.B. Lionheart
</center><p>

In this tutorial, we try to point out some
simple approaches that work with common, linear
regularization techniques. As the solution
strategy becomes more complex, then clearly there
become more advanced ways to cheat.

<h3>
Sample Problem: The happy transform
</h3>
To motivate the problem, assume that EIT measurement
data have been acquired from an image which resembles
a 'sad' face. Being of an optimistic outlook, we wish
that the image reconstructed represent a 'happy' face
instead. Fig. 1 illustrates this 'happy transform'.

<center>
<img height="128" src="tutorial210-sad.png" align="middle"> 
<font size="+4"><b>&rarr;</b></font>
<img height="128" src="tutorial210-happy.png" align="Middle"> 
<br>
<b>Fig. 1:</b>
The <i>happy transform</i>
</center><p>

<H3>
EIDORS Setup
</H3>

<p>
To configure EIDORS, we use the following code in Matlab.
Images are shown dark on a light background, so we set
the colours as follows:

<pre width="50">
&gt;&gt; run /path/to/eidors/start.m
&gt;&gt; calc_colours('backgnd',[1,1,1])
&gt;&gt; calc_colours('greylev',.01
</pre>

In order to simulate data for these images, we use
the following code for a small (256 element) face model:
<pre><!--#include virtual="tutorial210a.m" --></pre>
and for a larger (576 element) face model:
<pre><!--#include virtual="tutorial210b.m" --></pre>

<h3>
Approach #1: Careful selection of noise
</h3>

Typically, a reconstruction algorithm is presented
with white Gaussian noise (WGN) added to the data. One
technique to perform the happy transform is to
carefully select the noise.
In this case, we simulated a homogenous (v<sub>h</sub>)
and inhomogeneous (v<sub>i</sub>) data on a 256
element FEM. Subsequently 17.75dB of WGN was added to
v<sub>i</sub>, and the images reconstructed using
the algorithm of 
<a href="http://cvs.sourceforge.net/viewcvs.py/eidors3d/eidors3d/algorithms/aa_1996/">Adler and Guardo (1996)</a>.
Each image was reconstructed (with different selections of
hyperparameter values), and reviewed by the author to determine which cases
corresponded to the happy transform.

<pre><!--#include virtual="tutorial210c.m" --></pre>

 Fig. 2 shows two successful 'happy' images.
<center>
<img height="128" src="tutorial210-happynoise.png" >
<br>
<b>Fig. 2:</b>
Images with 17.75dB WGN which were selected as 'happy'
</center><p>

In order to determine the frequency of 'happy' noise, 2000
images were reviewed and 41 were selected, corresponding
to an occurance rate of approximately 2%.

While careful noise selection is not a mathematical/computational
technique, it is commonly used in association in research,
and thus merits mention here.

<h3>
Approach #2: Careful selection of priors
</h3>

The Bayesian framework for regularization interprets
the image penalty term as <i>a priori</i> information 
about the underlying image probability distribution.
In practice, however, this term is selected using
ad hoc or heuristic techniques. If the prior does
not correspond to the real case, then the reconstructed
image will be biased. This idea is key for approach #2.
<p>
In a Tikhonov regularization scheme, image amplitude
is penalized. We use the following formulation:
<center>
   <b>x</b> = (<b>H</b><sup>t</sup><b>H</b> +
                &lambda;<b>R</b>)<sup>&minus;1</sup>
               <b>H</b><sup>t</sup><b>y</b>
</center>
where the regularization term 
<center>
<b>R</b> = &radic;( trace <b>H</b><sup>t</sup><b>H</b> )
</center>

If, however, we <u>know</u> <i>a priori</i> that 
our data were measured from a happy face, then we 
would not wish to penalize image pixels which we
<u>know</u> to be large. Thus for each pixel <i>i</i>
in the happy face, we set 
<center>
<b>R</b><sub><i>i</i>,<i>i</i></sub> =
   &frac12; &radic;( trace <b>H</b><sup>t</sup><b>H</b>
                   )<sub><i>i</i>,<i>i</i></sub>
</center>

In order to implement this prior function with
EIDORS, we define function
<tt>tutorial210_cheat_tikhonov.m</tt> as follows
<pre><!--#include virtual="tutorial210_cheat_tikhonov.m" --></pre>

Images are reconstructed with this prior as follows:
<pre><!--#include virtual="tutorial210d.m" --></pre>

The effect of careful prior selection is hown in Fig. 3.
In this case, images were reconstructed on a 576 element
FEM (chosen to differ from the 256 element simulation mesh).

<center>
<img height="128" src="tikhonov.png" >
<br>
<b>Fig. 3:</b>
Reconstructed images illustrating the effect of image priors,
using <i>different</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Image 1:</i> Tikhonov prior with no weighting,
<i>Image 2:</i> Tikhonov prior with weighting for positions in sad face,
<i>Image 3:</i> Tikhonov prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Tikhonov prior with weighting for positions in happy face,
</center><p>

<p>
In order to enhance this effect, we use an <i>inverse crime</i>,
by putting the Tikhonov prior information <i>exactly</i> where
it needs to be to get the happy face (Fig. 4).

<center>
<img height="128" src="tikhonov-icrime.png" >
<br>
<b>Fig. 4:</b>
Reconstructed images illustrating the effect of image priors,
using <i>same</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Image 1:</i> Tikhonov prior with no weighting,
<i>Image 2:</i> Tikhonov prior with weighting for positions in sad face,
<i>Image 3:</i> Tikhonov prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Tikhonov prior with weighting for positions in happy face,
</center><p>

<h3>
Approach #3: Edge based priors
</h3>

It is somewhat difficult to properly model a Laplacian filter
on a Finite Element mesh, but one way to approximate it is to
do the following: for each edge between elements <i>i</i>
and <i>j</i>, put 1 at <i>i</i>,<i>i</i> and <i>j</i>,<i>j</i>
and &minus;1 at <i>i</i>,<i>j</i> and <i>j</i>,<i>i</i>.

<p>
Such a Laplacian filter can be used as a regularization prior
to penalize high frequency components (edges) in the image.
On the other hand, if we <i>know</i> where the edges are,
then edges should not be penalized (or be less penalized) in
those places. Fig 5 shows the effect of such careful
edge preserving prior selection (with no <i>inverse crime</i>).
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.

<center>
<img height="128" src="laplace3.png" >
<br>
<b>Fig. 5:</b>
Reconstructed images illustrating the effect of edge
preserving image priors,
using <i>different</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.
<i>Image 1:</i> Edge prior with no weighting,
<i>Image 2:</i> Edge prior with weighting for positions in sad face,
<i>Image 3:</i> Edge prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Edge prior with weighting for positions in happy face,
</center><p>

<p>
In order to enhance this effect, we use an <i>inverse crime</i>,
by putting the Tikhonov prior information <i>exactly</i> where
it needs to be to get the happy face (Fig. 6).
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.


<center>
<img height="128" src="laplace3-icrime.png" >
<br>
<b>Fig. 6:</b>
Reconstructed images illustrating the effect of edge
preserving image priors,
using <i>same</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Known edges</i> are weighted at 0.3&times;that of other
edges in the image.
<i>Image 1:</i> Edge prior with no weighting,
<i>Image 2:</i> Edge prior with weighting for positions in sad face,
<i>Image 3:</i> Edge prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Edge prior with weighting for positions in happy face,
</center><p>
<p>
An even more dramatic effect is obtained by setting the
penalty for <i>Known edges</i> to be zero (Fig. 7).

<center>
<img height="128" src="laplace0-icrime.png" >
<br>
<b>Fig. 7:</b>
Reconstructed images illustrating the effect of edge
preserving image priors,
using <i>same</i> mesh for model and reconstruction.
Images are numbered from left to right.
<i>Known edges</i> are weighted at 0.0&times;that of other
edges in the image.
<i>Image 1:</i> Edge prior with no weighting,
<i>Image 2:</i> Edge prior with weighting for positions in sad face,
<i>Image 3:</i> Edge prior with weighting for sad face (left) and
happy face (right),
<i>Image 4:</i> Edge prior with weighting for positions in happy face,
</center><p>



<h3>
Approach #4: Model mismatches
</h3>

Mismatches between measured (or simulated) data and the
reconstruction model can be an excellent way to introduce
artefacts into the reconstructed images. Perhaps the
most common occurance in EIT is when electrode positions
are not exactly where they were in the model.
<p>
In order to simulate this effect, the geometry of
the simulation model (based on 256 elements) was randomly
deformed in the radial direction based on the three low
order harmonics of the angle. Fig. 8 shows an example
of this effect.

The electrodes are positioned at a radial distance of 1.0
and underwent an average movement of 0.091&plusmn;0.035.
<center>
<img src="deform-grille.png" >
<br>
<b>Fig. 8:</b>
A finite element mesh deformed in the radial direction to
simulate the effect of model errors for electrode positions.
</center><p>

Simulations of model error were conducted and evaluated as
to whether they implemented the happy transform, as shown
in Fig. 9. Of 400 images, approximate 1% showed this effect. 

<center>
<img src="deform.png" height="128">
<br>
<b>Fig. 9:</b>
Sample images reconstucted from a deformed finite element
mesh. Some images were chosen which implement the happy
transform, while others were chosen because they appeared
humerous.
</center><p>

<h3>
Conclusion
</h3>

The goal of this document is to illustrate some of the things
that can go wrong with the algorithms provided with EIDORS.
While the treatment in this document is lighthearted, it
is surprisingly easy to unwittingly develop mathematical
algorithms which are subject to variants of these <i>cheats</i>.
We hope that these ideas will help clarify the kinds of
possible errors, and help researchers to avoid them.


</Body></html>
